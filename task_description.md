# 细粒度片段级中文仇恨言论识别任务

## 任务背景

仇恨言论是指个人或群体在互联网上发布的针对特定民族、种族、宗教、性别、性取向、残障人士等弱势群体的攻击性、贬低性或煽动性言论。
仇恨言论类型主要包括：

1. Sexism：针对性别的歧视言论
2. Racism：针对种族主义的歧视言论
3. Region：针对地域歧视的言论
4. LGBTQ：针对性取向歧视的言论
5. Others：其他歧视言论

## 任务内容

本次评测任务为**细粒度片段级中文仇恨言论识别**，基于给定的文本，任务的输入为社交媒体文本，输出为仇恨四元组，顺序依次为评论对象（Target）、论点（Argument）、目标群体（Targeted Group）、是否仇恨（Hateful）。具体说明如下：

**评论对象（Target）**：帖子的评述对象，如一个人或一个群体。当实例无具体目标时设为NULL。

**论点（Argument）**：包含对评论目标关键论点的信息片段。

**目标群体（Targeted Group）**：指包含仇恨信息的评论对象-论点对涉及的目标群体。标注的目标群体包括“地域”、“种族”、“性别”、“LGBTQ”、“其他”共5类。如样例1中包含了对LGBTQ群体和艾滋病群体的仇恨信息。

**是否仇恨（Hateful）**：评论对象-论点对是否构成了对某些群体的仇恨言论。

**对于非仇恨文本和不包含特定群体的一般攻击性言论，同样需要对目标群体和观点进行抽取，并设为Non-hate。由于样本中可能有多个评论对象，因此可以包含多个四元组。** 每个四元组中各个元素之间用" | "分割，并利用 [END] 结尾；如果一条样本中包含多个四元组，不同四元组之间利用 [SEP] 分割。**请严格按照顺序和格式提交，不要省略空格，以免影响成绩。**

下面提供两个数据样例：

> **输入：** 你可真是头蠢驴，这都做不好。
>
> **输出：** 你 | 蠢驴 | non-hate | non-hate [END]

> **输入：** 老黑我是真的讨厌，媚黑的还倒贴。
>
> **输出：** 老黑 | 讨厌 | Racism | hate [SEP] 媚黑的 | 倒贴 | Racism | hate [END]

将模型对测试集的输出内容按行保存到.txt文件中，如demo.txt文件。

**本次评测鼓励参赛者充分发挥开源闭源大模型的能力来解决任务，同时也欢迎基于小模型进行建模。**

## 评测数据

本次评测使用的中文仇恨言论四元组抽取数据集收集了贴吧、知乎等国内社交媒体平台的用户评论数据，为每条样本提供了高质量的二元分类标签，并对句子中的评论对象、论点和目标群体进行片段级标注。训练集在 train.json 文件中，测试集在 test1.json文件中。

## 评价指标

**评价指标为提交结果和标准答案的硬匹配和软匹配分别的F1分数，以及两种方式的F1分数的平均分**。计算方式与机器学习库sklearn一致。具体的计算公式如下：

F1-score:

$$
F1=2 \times \frac{P \times R}{P + R}
$$

**硬匹配：** 当且仅当预测四元组的每一个元素都与答案中对应元素**完全一致**才判断为正确抽取的四元组。

**软匹配：** 当且仅当预测四元组的 **Targeted Group , Hateful** 两个元素和标准答案中相对应的两个元素**完全一致**，并且预测四元组的 **Target ，Argument** 两个元素和标准答案中相对应的两个元素的字符串匹配程度超过50% 才判断为正确抽取的四元组。（计算方式为Python 标准库 difflib 模块中的 SequenceMatcher 函数一致）。具体计算如下：

$len_{pred}$: 预测四元组长度

$len_{gold}$: 标准答案长度

M：预测四元组和标准答案之间的最长公共子序列长度

Similarity：

$$
Similarity=\frac{M×2}{len_{pred}+len_{gold}}
$$
