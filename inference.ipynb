{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9b7ca-c2a4-4d8c-8e82-a0a24730af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载句向量模型 (这可能需要一些时间)...\n",
      "正在读取训练数据从 train_data.jsonl...\n",
      "正在将 4000 条训练数据编码为向量...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdbbf48e29a49d0aa5569ecc6060f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在保存FAISS索引到 'knowledge_base.index'\n",
      "知识库构建完成！\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"正在加载句向量模型\")\n",
    "model = SentenceTransformer('./text2vec_local', device='cuda')\n",
    "\n",
    "# 加载原始训练数据\n",
    "train_file = 'train_data.jsonl'\n",
    "print(f\"正在读取训练数据从 {train_file}...\")\n",
    "with open(train_file, 'r', encoding='utf-8') as f:\n",
    "    train_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# 提取需要被索引的内容和对应的答案\n",
    "user_contents = [entry['messages'][1]['content'] for entry in train_data]\n",
    "assistant_responses = [entry['messages'][2]['content'] for entry in train_data]\n",
    "\n",
    "print(f\"正在将 {len(user_contents)} 条训练数据编码为向量...\")\n",
    "embeddings = model.encode(user_contents, show_progress_bar=True, normalize_embeddings=True)\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "# 创建并构建FAISS索引\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"正在保存FAISS索引到 'knowledge_base.index'\")\n",
    "faiss.write_index(index, 'knowledge_base.index')\n",
    "\n",
    "# 同时保存原始内容以便后续查找\n",
    "knowledge_base_content = {\n",
    "    'user_inputs': user_contents,\n",
    "    'assistant_responses': assistant_responses\n",
    "}\n",
    "with open('knowledge_base_content.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(knowledge_base_content, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"知识库构建完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f66c4-f274-4b9e-bf73-bdff4ff6d69d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载检索工具...\n",
      "加载LLM中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaac1027971e40e08e794b2364285528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始使用SRAG进行推理，结果将写入 output_srag_augmented.txt\n",
      "[1/2000] 完成\n",
      "[2/2000] 完成\n",
      "[3/2000] 完成\n",
      "[4/2000] 完成\n",
      "[5/2000] 完成\n",
      "[6/2000] 完成\n",
      "[7/2000] 完成\n",
      "[8/2000] 完成\n",
      "[9/2000] 完成\n",
      "[10/2000] 完成\n",
      "[11/2000] 完成\n",
      "[12/2000] 完成\n",
      "[13/2000] 完成\n",
      "[14/2000] 完成\n",
      "[15/2000] 完成\n",
      "[16/2000] 完成\n",
      "[17/2000] 完成\n",
      "[18/2000] 完成\n",
      "[19/2000] 完成\n",
      "[20/2000] 完成\n",
      "[21/2000] 完成\n",
      "[22/2000] 完成\n",
      "[23/2000] 完成\n",
      "[24/2000] 完成\n",
      "[25/2000] 完成\n",
      "[26/2000] 完成\n",
      "[27/2000] 完成\n",
      "[28/2000] 完成\n",
      "[29/2000] 完成\n",
      "[30/2000] 完成\n",
      "[31/2000] 完成\n",
      "[32/2000] 完成\n",
      "[33/2000] 完成\n",
      "[34/2000] 完成\n",
      "[35/2000] 完成\n",
      "[36/2000] 完成\n",
      "[37/2000] 完成\n",
      "[38/2000] 完成\n",
      "[39/2000] 完成\n",
      "[40/2000] 完成\n",
      "[41/2000] 完成\n",
      "[42/2000] 完成\n",
      "[43/2000] 完成\n",
      "[44/2000] 完成\n",
      "[45/2000] 完成\n",
      "[46/2000] 完成\n",
      "[47/2000] 完成\n",
      "[48/2000] 完成\n",
      "[49/2000] 完成\n",
      "[50/2000] 完成\n",
      "[51/2000] 完成\n",
      "[52/2000] 完成\n",
      "[53/2000] 完成\n",
      "[54/2000] 完成\n",
      "[55/2000] 完成\n",
      "[56/2000] 完成\n",
      "[57/2000] 完成\n",
      "[58/2000] 完成\n",
      "[59/2000] 完成\n",
      "[60/2000] 完成\n",
      "[61/2000] 完成\n",
      "[62/2000] 完成\n",
      "[63/2000] 完成\n",
      "[64/2000] 完成\n",
      "[65/2000] 完成\n",
      "[66/2000] 完成\n",
      "[67/2000] 完成\n",
      "[68/2000] 完成\n",
      "[69/2000] 完成\n",
      "[70/2000] 完成\n",
      "[71/2000] 完成\n",
      "[72/2000] 完成\n",
      "[73/2000] 完成\n",
      "[74/2000] 完成\n",
      "[75/2000] 完成\n",
      "[76/2000] 完成\n",
      "[77/2000] 完成\n",
      "[78/2000] 完成\n",
      "[79/2000] 完成\n",
      "[80/2000] 完成\n",
      "[81/2000] 完成\n",
      "[82/2000] 完成\n",
      "[83/2000] 完成\n",
      "[84/2000] 完成\n",
      "[85/2000] 完成\n",
      "[86/2000] 完成\n",
      "[87/2000] 完成\n",
      "[88/2000] 完成\n",
      "[89/2000] 完成\n",
      "[90/2000] 完成\n",
      "[91/2000] 完成\n",
      "[92/2000] 完成\n",
      "[93/2000] 完成\n",
      "[94/2000] 完成\n",
      "[95/2000] 完成\n",
      "[96/2000] 完成\n",
      "[97/2000] 完成\n",
      "[98/2000] 完成\n",
      "[99/2000] 完成\n",
      "[100/2000] 完成\n",
      "[101/2000] 完成\n",
      "[102/2000] 完成\n",
      "[103/2000] 完成\n",
      "[104/2000] 完成\n",
      "[105/2000] 完成\n",
      "[106/2000] 完成\n",
      "[107/2000] 完成\n",
      "[108/2000] 完成\n",
      "[109/2000] 完成\n",
      "[110/2000] 完成\n",
      "[111/2000] 完成\n",
      "[112/2000] 完成\n",
      "[113/2000] 完成\n",
      "[114/2000] 完成\n",
      "[115/2000] 完成\n",
      "[116/2000] 完成\n",
      "[117/2000] 完成\n",
      "[118/2000] 完成\n",
      "[119/2000] 完成\n",
      "[120/2000] 完成\n",
      "[121/2000] 完成\n",
      "[122/2000] 完成\n",
      "[123/2000] 完成\n",
      "[124/2000] 完成\n",
      "[125/2000] 完成\n",
      "[126/2000] 完成\n",
      "[127/2000] 完成\n",
      "[128/2000] 完成\n",
      "[129/2000] 完成\n",
      "[130/2000] 完成\n",
      "[131/2000] 完成\n",
      "[132/2000] 完成\n",
      "[133/2000] 完成\n",
      "[134/2000] 完成\n",
      "[135/2000] 完成\n",
      "[136/2000] 完成\n",
      "[137/2000] 完成\n",
      "[138/2000] 完成\n",
      "[139/2000] 完成\n",
      "[140/2000] 完成\n",
      "[141/2000] 完成\n",
      "[142/2000] 完成\n",
      "[143/2000] 完成\n",
      "[144/2000] 完成\n",
      "[145/2000] 完成\n",
      "[146/2000] 完成\n",
      "[147/2000] 完成\n",
      "[148/2000] 完成\n",
      "[149/2000] 完成\n",
      "[150/2000] 完成\n",
      "[151/2000] 完成\n",
      "[152/2000] 完成\n",
      "[153/2000] 完成\n",
      "[154/2000] 完成\n",
      "[155/2000] 完成\n",
      "[156/2000] 完成\n",
      "[157/2000] 完成\n",
      "[158/2000] 完成\n",
      "[159/2000] 完成\n",
      "[160/2000] 完成\n",
      "[161/2000] 完成\n",
      "[162/2000] 完成\n",
      "[163/2000] 完成\n",
      "[164/2000] 完成\n",
      "[165/2000] 完成\n",
      "[166/2000] 完成\n",
      "[167/2000] 完成\n",
      "[168/2000] 完成\n",
      "[169/2000] 完成\n",
      "[170/2000] 完成\n",
      "[171/2000] 完成\n",
      "[172/2000] 完成\n",
      "[173/2000] 完成\n",
      "[174/2000] 完成\n",
      "[175/2000] 完成\n",
      "[176/2000] 完成\n",
      "[177/2000] 完成\n",
      "[178/2000] 完成\n",
      "[179/2000] 完成\n",
      "[180/2000] 完成\n",
      "[181/2000] 完成\n",
      "[182/2000] 完成\n",
      "[183/2000] 完成\n",
      "[184/2000] 完成\n",
      "[185/2000] 完成\n",
      "[186/2000] 完成\n",
      "[187/2000] 完成\n",
      "[188/2000] 完成\n",
      "[189/2000] 完成\n",
      "[190/2000] 完成\n",
      "[191/2000] 完成\n",
      "[192/2000] 完成\n",
      "[193/2000] 完成\n",
      "[194/2000] 完成\n",
      "[195/2000] 完成\n",
      "[196/2000] 完成\n",
      "[197/2000] 完成\n",
      "[198/2000] 完成\n",
      "[199/2000] 完成\n",
      "[200/2000] 完成\n",
      "[201/2000] 完成\n",
      "[202/2000] 完成\n",
      "[203/2000] 完成\n",
      "[204/2000] 完成\n",
      "[205/2000] 完成\n",
      "[206/2000] 完成\n",
      "[207/2000] 完成\n",
      "[208/2000] 完成\n",
      "[209/2000] 完成\n",
      "[210/2000] 完成\n",
      "[211/2000] 完成\n",
      "[212/2000] 完成\n",
      "[213/2000] 完成\n",
      "[214/2000] 完成\n",
      "[215/2000] 完成\n",
      "[216/2000] 完成\n",
      "[217/2000] 完成\n",
      "[218/2000] 完成\n",
      "[219/2000] 完成\n",
      "[220/2000] 完成\n",
      "[221/2000] 完成\n",
      "[222/2000] 完成\n",
      "[223/2000] 完成\n",
      "[224/2000] 完成\n",
      "[225/2000] 完成\n",
      "[226/2000] 完成\n",
      "[227/2000] 完成\n",
      "[228/2000] 完成\n",
      "[229/2000] 完成\n",
      "[230/2000] 完成\n",
      "[231/2000] 完成\n",
      "[232/2000] 完成\n",
      "[233/2000] 完成\n",
      "[234/2000] 完成\n",
      "[235/2000] 完成\n",
      "[236/2000] 完成\n",
      "[237/2000] 完成\n",
      "[238/2000] 完成\n",
      "[239/2000] 完成\n",
      "[240/2000] 完成\n",
      "[241/2000] 完成\n",
      "[242/2000] 完成\n",
      "[243/2000] 完成\n",
      "[244/2000] 完成\n",
      "[245/2000] 完成\n",
      "[246/2000] 完成\n",
      "[247/2000] 完成\n",
      "[248/2000] 完成\n",
      "[249/2000] 完成\n",
      "[250/2000] 完成\n",
      "[251/2000] 完成\n",
      "[252/2000] 完成\n",
      "[253/2000] 完成\n",
      "[254/2000] 完成\n",
      "[255/2000] 完成\n",
      "[256/2000] 完成\n",
      "[257/2000] 完成\n",
      "[258/2000] 完成\n",
      "[259/2000] 完成\n",
      "[260/2000] 完成\n",
      "[261/2000] 完成\n",
      "[262/2000] 完成\n",
      "[263/2000] 完成\n",
      "[264/2000] 完成\n",
      "[265/2000] 完成\n",
      "[266/2000] 完成\n",
      "[267/2000] 完成\n",
      "[268/2000] 完成\n",
      "[269/2000] 完成\n",
      "[270/2000] 完成\n",
      "[271/2000] 完成\n",
      "[272/2000] 完成\n",
      "[273/2000] 完成\n",
      "[274/2000] 完成\n",
      "[275/2000] 完成\n",
      "[276/2000] 完成\n",
      "[277/2000] 完成\n",
      "[278/2000] 完成\n",
      "[279/2000] 完成\n",
      "[280/2000] 完成\n",
      "[281/2000] 完成\n",
      "[282/2000] 完成\n",
      "[283/2000] 完成\n",
      "[284/2000] 完成\n",
      "[285/2000] 完成\n",
      "[286/2000] 完成\n",
      "[287/2000] 完成\n",
      "[288/2000] 完成\n",
      "[289/2000] 完成\n",
      "[290/2000] 完成\n",
      "[291/2000] 完成\n",
      "[292/2000] 完成\n",
      "[293/2000] 完成\n",
      "[294/2000] 完成\n",
      "[295/2000] 完成\n",
      "[296/2000] 完成\n",
      "[297/2000] 完成\n",
      "[298/2000] 完成\n",
      "[299/2000] 完成\n",
      "[300/2000] 完成\n",
      "[301/2000] 完成\n",
      "[302/2000] 完成\n",
      "[303/2000] 完成\n",
      "[304/2000] 完成\n",
      "[305/2000] 完成\n",
      "[306/2000] 完成\n",
      "[307/2000] 完成\n",
      "[308/2000] 完成\n",
      "[309/2000] 完成\n",
      "[310/2000] 完成\n",
      "[311/2000] 完成\n",
      "[312/2000] 完成\n",
      "[313/2000] 完成\n",
      "[314/2000] 完成\n",
      "[315/2000] 完成\n",
      "[316/2000] 完成\n",
      "[317/2000] 完成\n",
      "[318/2000] 完成\n",
      "[319/2000] 完成\n",
      "[320/2000] 完成\n",
      "[321/2000] 完成\n",
      "[322/2000] 完成\n",
      "[323/2000] 完成\n",
      "[324/2000] 完成\n",
      "[325/2000] 完成\n",
      "[326/2000] 完成\n",
      "[327/2000] 完成\n",
      "[328/2000] 完成\n",
      "[329/2000] 完成\n",
      "[330/2000] 完成\n",
      "[331/2000] 完成\n",
      "[332/2000] 完成\n",
      "[333/2000] 完成\n",
      "[334/2000] 完成\n",
      "[335/2000] 完成\n",
      "[336/2000] 完成\n",
      "[337/2000] 完成\n",
      "[338/2000] 完成\n",
      "[339/2000] 完成\n",
      "[340/2000] 完成\n",
      "[341/2000] 完成\n",
      "[342/2000] 完成\n",
      "[343/2000] 完成\n",
      "[344/2000] 完成\n",
      "[345/2000] 完成\n",
      "[346/2000] 完成\n",
      "[347/2000] 完成\n",
      "[348/2000] 完成\n",
      "[349/2000] 完成\n",
      "[350/2000] 完成\n",
      "[351/2000] 完成\n",
      "[352/2000] 完成\n",
      "[353/2000] 完成\n",
      "[354/2000] 完成\n",
      "[355/2000] 完成\n",
      "[356/2000] 完成\n",
      "[357/2000] 完成\n",
      "[358/2000] 完成\n",
      "[359/2000] 完成\n",
      "[360/2000] 完成\n",
      "[361/2000] 完成\n",
      "[362/2000] 完成\n",
      "[363/2000] 完成\n",
      "[364/2000] 完成\n",
      "[365/2000] 完成\n",
      "[366/2000] 完成\n",
      "[367/2000] 完成\n",
      "[368/2000] 完成\n",
      "[369/2000] 完成\n",
      "[370/2000] 完成\n",
      "[371/2000] 完成\n",
      "[372/2000] 完成\n",
      "[373/2000] 完成\n",
      "[374/2000] 完成\n",
      "[375/2000] 完成\n",
      "[376/2000] 完成\n",
      "[377/2000] 完成\n",
      "[378/2000] 完成\n",
      "[379/2000] 完成\n",
      "[380/2000] 完成\n",
      "[381/2000] 完成\n",
      "[382/2000] 完成\n",
      "[383/2000] 完成\n",
      "[384/2000] 完成\n",
      "[385/2000] 完成\n",
      "[386/2000] 完成\n",
      "[387/2000] 完成\n",
      "[388/2000] 完成\n",
      "[389/2000] 完成\n",
      "[390/2000] 完成\n",
      "[391/2000] 完成\n",
      "[392/2000] 完成\n",
      "[393/2000] 完成\n",
      "[394/2000] 完成\n",
      "[395/2000] 完成\n",
      "[396/2000] 完成\n",
      "[397/2000] 完成\n",
      "[398/2000] 完成\n",
      "[399/2000] 完成\n",
      "[400/2000] 完成\n",
      "[401/2000] 完成\n",
      "[402/2000] 完成\n",
      "[403/2000] 完成\n",
      "[404/2000] 完成\n",
      "[405/2000] 完成\n",
      "[406/2000] 完成\n",
      "[407/2000] 完成\n",
      "[408/2000] 完成\n",
      "[409/2000] 完成\n",
      "[410/2000] 完成\n",
      "[411/2000] 完成\n",
      "[412/2000] 完成\n",
      "[413/2000] 完成\n",
      "[414/2000] 完成\n",
      "[415/2000] 完成\n",
      "[416/2000] 完成\n",
      "[417/2000] 完成\n",
      "[418/2000] 完成\n",
      "[419/2000] 完成\n",
      "[420/2000] 完成\n",
      "[421/2000] 完成\n",
      "[422/2000] 完成\n",
      "[423/2000] 完成\n",
      "[424/2000] 完成\n",
      "[425/2000] 完成\n",
      "[426/2000] 完成\n",
      "[427/2000] 完成\n",
      "[428/2000] 完成\n",
      "[429/2000] 完成\n",
      "[430/2000] 完成\n",
      "[431/2000] 完成\n",
      "[432/2000] 完成\n",
      "[433/2000] 完成\n",
      "[434/2000] 完成\n",
      "[435/2000] 完成\n",
      "[436/2000] 完成\n",
      "[437/2000] 完成\n",
      "[438/2000] 完成\n",
      "[439/2000] 完成\n",
      "[440/2000] 完成\n",
      "[441/2000] 完成\n",
      "[442/2000] 完成\n",
      "[443/2000] 完成\n",
      "[444/2000] 完成\n",
      "[445/2000] 完成\n",
      "[446/2000] 完成\n",
      "[447/2000] 完成\n",
      "[448/2000] 完成\n",
      "[449/2000] 完成\n",
      "[450/2000] 完成\n",
      "[451/2000] 完成\n",
      "[452/2000] 完成\n",
      "[453/2000] 完成\n",
      "[454/2000] 完成\n",
      "[455/2000] 完成\n",
      "[456/2000] 完成\n",
      "[457/2000] 完成\n",
      "[458/2000] 完成\n",
      "[459/2000] 完成\n",
      "[460/2000] 完成\n",
      "[461/2000] 完成\n",
      "[462/2000] 完成\n",
      "[463/2000] 完成\n",
      "[464/2000] 完成\n",
      "[465/2000] 完成\n",
      "[466/2000] 完成\n",
      "[467/2000] 完成\n",
      "[468/2000] 完成\n",
      "[469/2000] 完成\n",
      "[470/2000] 完成\n",
      "[471/2000] 完成\n",
      "[472/2000] 完成\n",
      "[473/2000] 完成\n",
      "[474/2000] 完成\n",
      "[475/2000] 完成\n",
      "[476/2000] 完成\n",
      "[477/2000] 完成\n",
      "[478/2000] 完成\n",
      "[479/2000] 完成\n",
      "[480/2000] 完成\n",
      "[481/2000] 完成\n",
      "[482/2000] 完成\n",
      "[483/2000] 完成\n",
      "[484/2000] 完成\n",
      "[485/2000] 完成\n",
      "[486/2000] 完成\n",
      "[487/2000] 完成\n",
      "[488/2000] 完成\n",
      "[489/2000] 完成\n",
      "[490/2000] 完成\n",
      "[491/2000] 完成\n",
      "[492/2000] 完成\n",
      "[493/2000] 完成\n",
      "[494/2000] 完成\n",
      "[495/2000] 完成\n",
      "[496/2000] 完成\n",
      "[497/2000] 完成\n",
      "[498/2000] 完成\n",
      "[499/2000] 完成\n",
      "[500/2000] 完成\n",
      "[501/2000] 完成\n",
      "[502/2000] 完成\n",
      "[503/2000] 完成\n",
      "[504/2000] 完成\n",
      "[505/2000] 完成\n",
      "[506/2000] 完成\n",
      "[507/2000] 完成\n",
      "[508/2000] 完成\n",
      "[509/2000] 完成\n",
      "[510/2000] 完成\n",
      "[511/2000] 完成\n",
      "[512/2000] 完成\n",
      "[513/2000] 完成\n",
      "[514/2000] 完成\n",
      "[515/2000] 完成\n",
      "[516/2000] 完成\n",
      "[517/2000] 完成\n",
      "[518/2000] 完成\n",
      "[519/2000] 完成\n",
      "[520/2000] 完成\n",
      "[521/2000] 完成\n",
      "[522/2000] 完成\n",
      "[523/2000] 完成\n",
      "[524/2000] 完成\n",
      "[525/2000] 完成\n",
      "[526/2000] 完成\n",
      "[527/2000] 完成\n",
      "[528/2000] 完成\n",
      "[529/2000] 完成\n",
      "[530/2000] 完成\n",
      "[531/2000] 完成\n",
      "[532/2000] 完成\n",
      "[533/2000] 完成\n",
      "[534/2000] 完成\n",
      "[535/2000] 完成\n",
      "[536/2000] 完成\n",
      "[537/2000] 完成\n",
      "[538/2000] 完成\n",
      "[539/2000] 完成\n",
      "[540/2000] 完成\n",
      "[541/2000] 完成\n",
      "[542/2000] 完成\n",
      "[543/2000] 完成\n",
      "[544/2000] 完成\n",
      "[545/2000] 完成\n",
      "[546/2000] 完成\n",
      "[547/2000] 完成\n",
      "[548/2000] 完成\n",
      "[549/2000] 完成\n",
      "[550/2000] 完成\n",
      "[551/2000] 完成\n",
      "[552/2000] 完成\n",
      "[553/2000] 完成\n",
      "[554/2000] 完成\n",
      "[555/2000] 完成\n",
      "[556/2000] 完成\n",
      "[557/2000] 完成\n",
      "[558/2000] 完成\n",
      "[559/2000] 完成\n",
      "[560/2000] 完成\n",
      "[561/2000] 完成\n",
      "[562/2000] 完成\n",
      "[563/2000] 完成\n",
      "[564/2000] 完成\n",
      "[565/2000] 完成\n",
      "[566/2000] 完成\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ============ 1. 加载知识库和检索模型 ============\n",
    "print(\"正在加载检索工具...\")\n",
    "retrieval_model = SentenceTransformer('./text2vec_local', device='cuda')\n",
    "index = faiss.read_index('knowledge_base.index')\n",
    "with open('knowledge_base_content.json', 'r', encoding='utf-8') as f:\n",
    "    knowledge_base = json.load(f)\n",
    "\n",
    "# ============ 2. 路径和模型配置 (与您原版相同) ============\n",
    "base_model_path = \"./Qwen3-8B\"\n",
    "lora_model_path = \"./qwen3-8b-lora-finetuned-2/final_checkpoint\"\n",
    "test_file_path = \"test1.json\"\n",
    "output_file_path = \"output_srag_augmented.txt\" # 使用新文件名以作区分\n",
    "\n",
    "# 基础的 System Prompt\n",
    "base_system_prompt = (\n",
    "    \"请从文本中抽取仇恨言论四元组，要求：\\n\"\n",
    "    \"1. 严格按照以下格式回复：(评论对象 | 论点 | 目标群体 | 是否仇恨 [END])，直接输出，不要解释。\\n\"\n",
    "    \"2. 如有多个四元组，两两之间用[SEP]分隔。\\n\"\n",
    "    \"3. 目标群体可以包含以下6项中的一项或多项：Region、Racism、Sexism、LGBTQ、others、non-hate。\"\n",
    "    \"注意仅当‘是否仇恨’项为‘non-hate’时，‘目标群体’项才为‘non-hate’。\"\n",
    ")\n",
    "\n",
    "# ============ 3. 加载LLM============\n",
    "print(\"加载LLM中...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# ============ 4. 读取测试数据============\n",
    "with open(test_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# ============ 5. 批量推理主循环 (集成SRAG) ============\n",
    "print(f\"开始使用SRAG进行推理，结果将写入 {output_file_path}\")\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    for idx, example in enumerate(test_data):\n",
    "        user_input = example[\"content\"]\n",
    "\n",
    "        # --- SRAG核心: 检索与构建Prompt ---\n",
    "        # a. 将当前输入编码为向量\n",
    "        query_embedding = retrieval_model.encode([user_input], normalize_embeddings=True).astype('float32')\n",
    "        \n",
    "        # b. 在FAISS中搜索最相似的2个例子\n",
    "        k = 2\n",
    "        distances, indices = index.search(query_embedding, k)\n",
    "        \n",
    "        # c. 构建 few-shot 范例\n",
    "        few_shot_examples = \"下面是一些范例，仅供参考，请学习它们的格式，但要根据新的用户输入来生成内容。：\\n---\"\n",
    "        for i in indices[0]:\n",
    "            retrieved_input = knowledge_base['user_inputs'][i]\n",
    "            retrieved_output = knowledge_base['assistant_responses'][i]\n",
    "            few_shot_examples += f\"\\n[样例输入]: {retrieved_input}\\n[样例输出]: {retrieved_output}\\n---\"\n",
    "        \n",
    "        # d. 组合成最终的system prompt\n",
    "        final_system_prompt = f\"{base_system_prompt}\\n\\n{few_shot_examples}\"\n",
    "        \n",
    "        full_prompt = (\n",
    "            f\"<|im_start|>system\\n{final_system_prompt}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>user\\n{user_input}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "        \n",
    "        inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=128,\n",
    "                do_sample=True,\n",
    "                temperature=0.2,\n",
    "                top_p=0.7,\n",
    "                repetition_penalty=1.1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "        final_line = response.strip().split('\\n')[-1] # 提取最后一行有效输出\n",
    "        out_file.write(final_line + \"\\n\")\n",
    "        print(f\"[{idx+1}/{len(test_data)}] 完成\")\n",
    "\n",
    "print(\"全部推理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3172ac6d-e216-4520-87cd-b058a81b041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "🔍 正在诊断输入: '有这样的话？如果是这样的，那就是卫辉官媒的错误。但是，你是不是在造谣。请给出网址以供查阅。'\n",
      "=============================================\n",
      "\n",
      "--- 检索到的范例 ---\n",
      "  范例 1 (相似度: 0.7539):\n",
      "    输入: '那你这不是造谣吗'\n",
      "    输出: '你 | 造谣 | non-hate | non-hate [END]'\n",
      "\n",
      "  范例 2 (相似度: 0.7190):\n",
      "    输入: '而且网民根本不会过问你之前经历了多少，只会拿一句【不管怎么说也不能打人】来否认你之前承受过的所有折磨，【不能打人】这一句就是【无论如何都是你有罪】的最大筹码'\n",
      "    输出: '不能打人 | 【无论如何都是你有罪】的最大筹码 | non-hate | non-hate [END]'\n",
      "\n",
      "--- 最终生成的完整Prompt ---\n",
      "<|im_start|>system\n",
      "请从文本中抽取仇恨言论四元组，要求：\n",
      "1. 严格按照以下格式回复：(评论对象 | 论点 | 目标群体 | 是否仇恨 [END])，直接输出，不要解释。\n",
      "2. 如有多个四元组，两两之间用[SEP]分隔。\n",
      "3. 目标群体可以包含以下6项中的一项或多项：Region、Racism、Sexism、LGBTQ、others、non-hate。注意仅当‘是否仇恨’项为‘non-hate’时，‘目标群体’项才为‘non-hate’。\n",
      "\n",
      "下面是一些格式正确的范例：\n",
      "---\n",
      "[范例输入]: 那你这不是造谣吗\n",
      "[范例输出]: 你 | 造谣 | non-hate | non-hate [END]\n",
      "---\n",
      "[范例输入]: 而且网民根本不会过问你之前经历了多少，只会拿一句【不管怎么说也不能打人】来否认你之前承受过的所有折磨，【不能打人】这一句就是【无论如何都是你有罪】的最大筹码\n",
      "[范例输出]: 不能打人 | 【无论如何都是你有罪】的最大筹码 | non-hate | non-hate [END]\n",
      "---\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "有这样的话？如果是这样的，那就是卫辉官媒的错误。但是，你是不是在造谣。请给出网址以供查阅。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "base_system_prompt = (\n",
    "    \"请从文本中抽取仇恨言论四元组，要求：\\n\"\n",
    "    \"1. 严格按照以下格式回复：(评论对象 | 论点 | 目标群体 | 是否仇恨 [END])，直接输出，不要解释。\\n\"\n",
    "    \"2. 如有多个四元组，两两之间用[SEP]分隔。\\n\"\n",
    "    \"3. 目标群体可以包含以下6项中的一项或多项：Region、Racism、Sexism、LGBTQ、others、non-hate。\"\n",
    "    \"注意仅当‘是否仇恨’项为‘non-hate’时，‘目标群体’项才为‘non-hate’。\"\n",
    ")\n",
    "\n",
    "retrieval_model = SentenceTransformer('./text2vec_local', device='cuda')\n",
    "index = faiss.read_index('knowledge_base.index')\n",
    "with open('knowledge_base_content.json', 'r', encoding='utf-8') as f:\n",
    "    knowledge_base = json.load(f)\n",
    "\n",
    "def debug_srag_case(user_input_text):\n",
    "    \"\"\"\n",
    "    这个函数接收一个用户输入，执行SRAG流程，并打印出所有中间信息以供分析。\n",
    "    \"\"\"\n",
    "    print(\"=============================================\")\n",
    "    print(f\"🔍 正在诊断输入: '{user_input_text}'\")\n",
    "    print(\"=============================================\\n\")\n",
    "\n",
    "    # --- 1. 检索 ---\n",
    "    query_embedding = retrieval_model.encode([user_input_text], normalize_embeddings=True).astype('float32')\n",
    "    k = 2\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    print(\"--- 检索到的范例 ---\")\n",
    "    retrieved_examples_text = \"\"\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        retrieved_input = knowledge_base['user_inputs'][idx]\n",
    "        retrieved_output = knowledge_base['assistant_responses'][idx]\n",
    "        print(f\"  范例 {i+1} (相似度: {distances[0][i]:.4f}):\")\n",
    "        print(f\"    输入: '{retrieved_input}'\")\n",
    "        print(f\"    输出: '{retrieved_output}'\\n\")\n",
    "        retrieved_examples_text += f\"[范例输入]: {retrieved_input}\\n[范例输出]: {retrieved_output}\\n---\\n\"\n",
    "\n",
    "    # --- 2. 构建完整Prompt ---\n",
    "    final_system_prompt = f\"{base_system_prompt}\\n\\n下面是一些格式正确的范例：\\n---\\n{retrieved_examples_text}\"\n",
    "    full_prompt = (\n",
    "        f\"<|im_start|>system\\n{final_system_prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{user_input_text}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "    \n",
    "    print(\"--- 最终生成的完整Prompt ---\")\n",
    "    print(full_prompt)\n",
    "    print(\"=============================================\")\n",
    "\n",
    "\n",
    "# --- 使用方法 ---\n",
    "# 假设你已经加载了所有模型和知识库\n",
    "# 从你的测试集中找一个得分变低的例子\n",
    "failed_example_text = \"有这样的话？如果是这样的，那就是卫辉官媒的错误。但是，你是不是在造谣。请给出网址以供查阅。\"\n",
    "debug_srag_case(failed_example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db3bde-f76a-40a4-9e25-44e26b658f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
