
# **CCL25-Eval 任务10：细粒度中文仇恨言论识别**

本项目是为**CCL25-Eval 任务10：细粒度中文仇恨言论识别**所开发的一套完整的解决方案。方案核心是利用大型语言模型**Qwen3-8B**，通过**LoRA高效微调**、**对抗性数据增强**以及**自检索增强生成（SRAG）**等一系列技术，实现对中文网络仇恨言论的精准识别与结构化提取。

## **项目亮点** ✨

- **前沿模型应用**：选用Qwen3-8B作为基座模型，利用其强大的中文理解能力。
- **高效参数微调**：采用LoRA技术，在有限的计算资源下高效地完成了模型的领域自适应。
- [cite_start]**定制化数据增强**：针对中文网络“黑话”频现的特点，构建了**对抗性词典** [cite: 1, 2]，将4000条训练数据扩充至近8000条，显著提升了模型的鲁棒性。
- **创新的推理策略**：引入**自检索增强生成（SRAG）**模块，通过在推理时提供上下文范例，有效提升了模型输出的准确性和格式稳定性。

## **文件结构** 📂

```
.
├── data_reinforce.ipynb      # 数据增强脚本，用于生成扩充数据集
├── inference.ipynb           # 最终的推理脚本，集成了SRAG模块
├── train.ipynb               # 核心训练脚本，包含基线模型和增强模型的训练流程
├── train.json                # 原始训练数据集
├── test1.json                # 测试数据集
├── train_huggingface_format.json # 转换为Hugging Face格式的训练数据
├── task_description.md       # 任务官方描述文件
└── README.md                 # (本项目说明文件)
```

## **实现步骤** 🚀

### **1. 环境配置**

首先，请根据`train.ipynb`等文件中的`import`语句，安装所有必需的Python库。关键库包括：

```bash
pip install torch transformers datasets peft trl sentence-transformers faiss-cpu
```

### **2. 数据增强 (可选但推荐)**

[cite_start]直接运行`data_reinforce.ipynb` [cite: 3][cite_start]可以对原始的`train.json` [cite: 4]进行数据增强。脚本的核心是利用一个**对抗性词典**，对原始句子进行“黑话”和标准词之间的随机替换。

- **输入**: `train.json`
- **输出**: 一个扩充后的训练文件（例如 `train_augmented.jsonl`）

这一步极大地丰富了数据的多样性，是提升模型鲁棒性的关键。

### **3. 模型训练**

[cite_start]`train.ipynb` [cite: 5]是本项目的核心训练文件。

- **加载数据**：脚本会加载处理后的训练数据。为获得最佳性能，建议使用第2步中生成的增强数据集。
- **模型配置**：定义Qwen3-8B模型、Tokenizer，并配置LoRA参数。
- **开始训练**：使用`SFTTrainer`进行模型微调。训练完成后，LoRA权重文件将被保存在指定的输出目录中。

### **4. 推理与评估**

[cite_start]`inference.ipynb` [cite: 6]用于在测试集上进行推理和评估。

- **加载模型**：脚本会加载原始的Qwen3-8B基座模型，并合并已训练好的LoRA权重。
- **构建SRAG知识库**：在首次运行时，脚本会使用训练数据构建一个FAISS向量索引库，为SRAG提供检索支持。
- [cite_start]**执行推理**：对于`test1.json` [cite: 7]中的每一条数据，SRAG模块会先从知识库中检索最相似的范例，然后将范例和原始数据一同输入模型，生成最终的四元组结果。
- **输出**: 结果将被保存在一个`.txt`文件中，可直接用于提交至评测系统。

## **核心方法简介**

### **对抗性数据增强**

我们发现，网络仇恨言论为了规避审查，大量使用谐音、拆字、缩写等“黑话”。传统模型难以识别。我们通过分析训练数据，构建了一个“黑话”<->“标准词”的映射词典，并以此对训练样本进行随机替换，模拟了真实的网络语言环境，显著提升了模型的识别能力。

### **自检索增强生成 (SRAG)**

为了解决模型在生成高度结构化的四元组时格式不稳定或在模糊情境下判断不准的问题，我们引入了SRAG。该方法在推理时，先从训练集中检索出与当前任务最相似的K个“成功案例”，然后将这些案例作为“上下文范例”一并提供给模型。这相当于给模型一个“参考答案”，有效引导其做出更准确、格式更规范的输出。
